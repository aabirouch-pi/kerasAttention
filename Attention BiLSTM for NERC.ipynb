{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Attention mechanisms to an LSTM network \n",
    "\n",
    "We will be working with the following dataset:\n",
    "\n",
    "https://www.kaggle.com/gagandeep16/ner-using-bidirectional-lstm\n",
    "\n",
    "annotated for the task of Named Entity Recognition\n",
    "\n",
    "The objetive of this notebook is to build a prototype LSTM for sequence labeling, and apply a very simple attention mechanisms before the recurrent layer.\n",
    "\n",
    "Once the model is trained, we show the attention score for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading dataset and extracting sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milagro/miniconda2/envs/am_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataset = pandas.read_csv(\"../ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False,\n",
    "                          usecols=['sentence_idx', 'word', 'pos', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050796, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNS</td>\n",
       "      <td>1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NNS</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VBP</td>\n",
       "      <td>1</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VBN</td>\n",
       "      <td>1</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>through</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>London</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TO</td>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VB</td>\n",
       "      <td>1</td>\n",
       "      <td>protest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>war</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>VB</td>\n",
       "      <td>1</td>\n",
       "      <td>demand</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "      <td>British</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NNS</td>\n",
       "      <td>1</td>\n",
       "      <td>troops</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pos sentence_idx           word    tag\n",
       "0   NNS            1      Thousands      O\n",
       "1    IN            1             of      O\n",
       "2   NNS            1  demonstrators      O\n",
       "3   VBP            1           have      O\n",
       "4   VBN            1        marched      O\n",
       "5    IN            1        through      O\n",
       "6   NNP            1         London  B-geo\n",
       "7    TO            1             to      O\n",
       "8    VB            1        protest      O\n",
       "9    DT            1            the      O\n",
       "10   NN            1            war      O\n",
       "11   IN            1             in      O\n",
       "12  NNP            1           Iraq  B-geo\n",
       "13   CC            1            and      O\n",
       "14   VB            1         demand      O\n",
       "15   DT            1            the      O\n",
       "16   NN            1     withdrawal      O\n",
       "17   IN            1             of      O\n",
       "18   JJ            1        British  B-gpe\n",
       "19  NNS            1         troops      O"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentenceFactory(object):\n",
    "    \n",
    "    def __init__(self, dataset, tag_preprocess=lambda x: x):\n",
    "        self.dataset = dataset\n",
    "        agg_func = lambda s: [\n",
    "            (w, p, tag_preprocess(t)) \n",
    "            for w, p, t in zip(s[\"word\"].values.tolist(), s['pos'].values.tolist(),\n",
    "                             s[\"tag\"].values.tolist())\n",
    "        ]\n",
    "        grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
    "        self.sentences = [s for s in grouped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a list of sentences from the dataset and we replace the BIO tag format for a regular label type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Thousands', 'NNS', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('demonstrators', 'NNS', 'O'),\n",
       "  ('have', 'VBP', 'O'),\n",
       "  ('marched', 'VBN', 'O'),\n",
       "  ('through', 'IN', 'O'),\n",
       "  ('London', 'NNP', 'geo'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('protest', 'VB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('war', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('Iraq', 'NNP', 'geo'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('demand', 'VB', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('withdrawal', 'NN', 'O'),\n",
       "  ('of', 'IN', 'O'),\n",
       "  ('British', 'JJ', 'gpe'),\n",
       "  ('troops', 'NNS', 'O'),\n",
       "  ('from', 'IN', 'O'),\n",
       "  ('that', 'DT', 'O'),\n",
       "  ('country', 'NN', 'O'),\n",
       "  ('.', '.', 'O')]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_bio = lambda x: x.replace('I-', '').replace('B-', '')\n",
    "\n",
    "instances = SentenceFactory(dataset, tag_preprocess=remove_bio).sentences\n",
    "\n",
    "instances[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sentence_length = dataset.groupby('sentence_idx').word.count().max()\n",
    "max_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 30175\n"
     ]
    }
   ],
   "source": [
    "unique_words = dataset.word.unique()\n",
    "unique_words = numpy.append(unique_words, \"ENDPAD\")\n",
    "print('Vocabulary size {}'.format(unique_words.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'geo' 'gpe' 'per' 'org' 'tim' 'art' 'nat' 'eve' 'prev-prev-lemma']\n",
      "Unique labels 10\n"
     ]
    }
   ],
   "source": [
    "labels = dataset.tag.fillna('O').apply(remove_bio).unique()\n",
    "print(labels)\n",
    "print('Unique labels {}'.format(labels.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the input sequences\n",
    "\n",
    "To train more effectively the network, we pad all sequences to have the same lenght. In this case, we choose to use the lenght of the longest sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(unique_words)}\n",
    "labels2idx = {t: i for i, t in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_matrix = [[word2idx[w[0]] for w in s] for s in instances]\n",
    "x_matrix = pad_sequences(maxlen=max_sentence_length, sequences=x_matrix,\n",
    "                         padding=\"post\", value=unique_words.shape[0] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     2, ..., 30174, 30174, 30174],\n",
       "       [   22,     1,    23, ..., 30174, 30174, 30174],\n",
       "       [   42,     4,    18, ..., 30174, 30174, 30174],\n",
       "       ..., \n",
       "       [   61,   921,   151, ..., 30174, 30174, 30174],\n",
       "       [  531,   330,     3, ..., 30174, 30174, 30174],\n",
       "       [18519, 30174, 30174, ..., 30174, 30174, 30174]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [[labels2idx[w[2]] for w in s] for s in instances]\n",
    "y = pad_sequences(maxlen=140, sequences=y, padding=\"post\", value=labels2idx[\"O\"])\n",
    "y = [to_categorical(i, num_classes=labels.shape[0]) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_matrix, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Building the model\n",
    "\n",
    "We build a model with an object oriented interface so we can add and remove layers in sub-classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BiLSTM(object):\n",
    "    def __init__(self, vocabulary_size, max_sentence_length, labels,\n",
    "                 embedding_size=50):\n",
    "        self.model = None\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.labels = labels\n",
    "        self.n_labels = labels.shape[0]\n",
    "        \n",
    "    def add_embedding_layer(self, layers):\n",
    "        layers = Embedding(\n",
    "            input_dim=self.vocabulary_size,\n",
    "            output_dim=self.max_sentence_length,\n",
    "            input_length=self.max_sentence_length)(layers)\n",
    "        return Dropout(0.1)(layers)\n",
    "    \n",
    "    def add_recurrent_layer(self, layers):\n",
    "        return Bidirectional(\n",
    "            LSTM(units=100, return_sequences=True,\n",
    "                 recurrent_dropout=0.1))(layers)\n",
    "    \n",
    "    def add_output_layer(self, layers):\n",
    "        return TimeDistributed(\n",
    "            Dense(self.n_labels, activation=\"softmax\"))(layers)\n",
    "    \n",
    "    def build(self):\n",
    "        input = Input(shape=(self.max_sentence_length,))\n",
    "        layers = self.add_embedding_layer(input)\n",
    "        layers = self.add_recurrent_layer(layers)\n",
    "        layers = self.add_output_layer(layers)        \n",
    "        \n",
    "        self.model = Model(input, layers)\n",
    "        self.model.compile(\n",
    "            optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "    \n",
    "    def fit(self, X_train, y_train, epochs, batch_size=32, validation_split=0.2):\n",
    "        if self.model is None:\n",
    "            self.build()\n",
    "        return self.model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                              validation_split=validation_split, verbose=1)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return numpy.argmax(self.model.predict(X_test), axis=-1)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predictions = numpy.argmax(self.model.predict(X_test), axis=-1).flatten()\n",
    "        true_labels = numpy.argmax(y_test, axis=-1).flatten()\n",
    "        print(metrics.classification_report(true_labels, predictions,\n",
    "                                            target_names=self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 2.2358 - acc: 0.5758 - val_loss: 2.0373 - val_acc: 0.9732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83652d0390>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM(vocabulary_size=unique_words.shape[0],\n",
    "               max_sentence_length=max_sentence_length,\n",
    "               labels=labels)\n",
    "size = 100\n",
    "model.fit(X_train[:size], numpy.array(y_train[:size]), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'geo', 'gpe', 'per', 'org', 'tim', 'art', 'nat', 'eve',\n",
       "       'prev-prev-lemma'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "              O       0.97      1.00      0.98     13577\n",
      "            geo       0.00      0.00      0.00       114\n",
      "            gpe       0.00      0.00      0.00        42\n",
      "            per       0.00      0.00      0.00        93\n",
      "            org       0.00      0.00      0.00        94\n",
      "            tim       0.00      0.00      0.00        75\n",
      "            art       0.00      0.00      0.00         3\n",
      "            nat       0.00      0.00      0.00         2\n",
      "\n",
      "    avg / total       0.94      0.97      0.95     14000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milagro/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test[:size], y_test[:size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            : (True) : Pred\n",
      "The             : O      : O     \n",
      "Latvians        : gpe    : O     \n",
      "needed          : O      : O     \n",
      "to              : O      : O     \n",
      "beat            : O      : O     \n",
      "Kazakhstan      : geo    : O     \n",
      "and             : O      : O     \n",
      "erase           : O      : O     \n",
      "a               : O      : O     \n",
      "huge            : O      : O     \n",
      "16-goal         : O      : O     \n",
      "margin          : O      : O     \n",
      "while           : O      : O     \n",
      "hoping          : O      : O     \n",
      "the             : O      : O     \n",
      "United          : geo    : O     \n",
      "States          : geo    : O     \n",
      "would           : O      : O     \n",
      "lose            : O      : O     \n",
      "against         : O      : O     \n",
      "Russia          : geo    : O     \n",
      "later           : O      : O     \n",
      "in              : O      : O     \n",
      "the             : O      : O     \n",
      "day             : tim    : O     \n",
      ".               : O      : O     \n",
      "The             : O      : O     \n",
      "Latvians        : gpe    : O     \n",
      "needed          : O      : O     \n",
      "to              : O      : O     \n",
      "beat            : O      : O     \n",
      "Kazakhstan      : geo    : O     \n",
      "and             : O      : O     \n",
      "erase           : O      : O     \n",
      "a               : O      : O     \n",
      "huge            : O      : O     \n",
      "16-goal         : O      : O     \n",
      "margin          : O      : O     \n",
      "while           : O      : O     \n",
      "hoping          : O      : O     \n",
      "the             : O      : O     \n",
      "United          : geo    : O     \n",
      "States          : geo    : O     \n",
      "would           : O      : O     \n",
      "lose            : O      : O     \n",
      "against         : O      : O     \n",
      "Russia          : geo    : O     \n",
      "later           : O      : O     \n",
      "in              : O      : O     \n",
      "the             : O      : O     \n",
      "day             : tim    : O     \n",
      ".               : O      : O     \n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "p = model.predict(numpy.array([X_test[i]]))\n",
    "print(\"{:15} : ({:4}) : {}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "for w, true, pred in zip(X_test[i], y_test[i], p[i]):\n",
    "    if w == len(unique_words) - 1:\n",
    "        break\n",
    "    print(\"{:15} : {:6} : {:6}\".format(unique_words[w], labels[numpy.argmax(true)], labels[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Add an attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Lambda, Permute, RepeatVector, merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttBiLSTM(BiLSTM):\n",
    "    \n",
    "    def add_attention_block(self, layers):\n",
    "        \"\"\"Apply an attention block to a partial model layers.\"\"\"\n",
    "        feature_vector_size = K.int_shape(layers)[-1]\n",
    "        att_layer = TimeDistributed(\n",
    "            Dense(feature_vector_size, activation=None),\n",
    "            name='attention_matrix_score')(layers)\n",
    "        # Calculate a single score for each timestep\n",
    "        att_layer = Lambda(lambda x: K.mean(x, axis=2),\n",
    "                           name='attention_vector_score')(att_layer)\n",
    "        # Reshape to obtain the same shape as input\n",
    "        att_layer = Permute((2, 1))(\n",
    "            RepeatVector(feature_vector_size)(att_layer))\n",
    "        layers = merge([att_layer, layers],  mode='mul')\n",
    "        return layers \n",
    "    \n",
    "    def add_embedding_layer(self, layers):\n",
    "        layers = super(AttBiLSTM, self).add_embedding_layer(layers)        \n",
    "        return self.add_attention_block(layers)\n",
    "    \n",
    "    def attention_predict(self, input_sequences):\n",
    "        \"\"\"Classifies the input sequences and returns the attention score.\n",
    "\n",
    "        Args:\n",
    "            model: a Keras model\n",
    "            input_: a list of array representation of sentences.\n",
    "\n",
    "        Returns:\n",
    "            A tuple where the first element is the attention scores for each\n",
    "            sentence, and the second is the model predictions.\n",
    "        \"\"\"\n",
    "        layer = self.model.get_layer('attention_vector_score')\n",
    "        attention_model = Model(\n",
    "            inputs=self.model.input, outputs=[layer.output, self.model.output])\n",
    "        # The attention output is (batch_size, timesteps, features)\n",
    "        return attention_model.predict(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milagro/miniconda2/envs/am_env/lib/python3.5/site-packages/ipykernel/__main__.py:15: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/milagro/miniconda2/envs/am_env/lib/python3.5/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 2.2890 - acc: 0.5897 - val_loss: 2.2442 - val_acc: 0.9732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f835727c2e8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AttBiLSTM(vocabulary_size=unique_words.shape[0],\n",
    "               max_sentence_length=max_sentence_length,\n",
    "               labels=labels)\n",
    "size = 100\n",
    "model.fit(X_train[:size], numpy.array(y_train[:size]), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attention, predictions = model.attention_predict(numpy.array(X_test[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 140)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Visualize the attention\n",
    "\n",
    "First, we align the attention and labels output from the network, and remove all the padding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "# This could be done in a much more compact code, but I hope this is more\n",
    "# understandable\n",
    "for sentence_idx, (word_idxs, sentence_a_scores, sentence_labels) in enumerate(\n",
    "        zip(X_test[0:2], attention, numpy.argmax(predictions, axis=-1))):\n",
    "    for word_idx, a_score, label_idx in zip(word_idxs, sentence_a_scores, sentence_labels):\n",
    "        word = unique_words[word_idx]\n",
    "        if word == 'ENDPAD':\n",
    "            break\n",
    "        label = labels[label_idx]\n",
    "        result.append((word, a_score, sentence_idx, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a stand alone service, we first must store the results in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas.DataFrame(result, columns=['token', 'attention', 'sentence', 'label']).to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualizing attention in notebook\n",
    "\n",
    "Another option is to import d3 directly into the notebook, but it is less robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from string import Template\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"js/d3.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<script src=\"js/d3.min.js\"></script>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"js/textChart.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<script src=\"js/textChart.js\"></script>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "if (d3 === undefined) {\n",
       "    alert('No d3 library');\n",
       "}\n",
       "if (TextChart === undefined) {\n",
       "    alert('No Chart library');\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"<script>\n",
    "if (d3 === undefined) {\n",
    "    alert('No d3 library');\n",
    "}\n",
    "if (TextChart === undefined) {\n",
    "    alert('No Chart library');\n",
    "}\n",
    "</script>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = pandas.DataFrame(\n",
    "    result, columns=['token', 'attention', 'sentence', 'label']).to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div id='text-container'></div>\n",
       "    <script>\n",
       "var nouns = [{\"token\":\"The\",\"attention\":-0.0036663993,\"sentence\":0,\"label\":\"O\"},{\"token\":\"Latvians\",\"attention\":0.002276656,\"sentence\":0,\"label\":\"O\"},{\"token\":\"needed\",\"attention\":0.0017944238,\"sentence\":0,\"label\":\"O\"},{\"token\":\"to\",\"attention\":-0.001162009,\"sentence\":0,\"label\":\"O\"},{\"token\":\"beat\",\"attention\":-0.0009340789,\"sentence\":0,\"label\":\"O\"},{\"token\":\"Kazakhstan\",\"attention\":0.0000199094,\"sentence\":0,\"label\":\"O\"},{\"token\":\"and\",\"attention\":0.0013523418,\"sentence\":0,\"label\":\"O\"},{\"token\":\"erase\",\"attention\":0.0040595364,\"sentence\":0,\"label\":\"O\"},{\"token\":\"a\",\"attention\":0.0014214688,\"sentence\":0,\"label\":\"O\"},{\"token\":\"huge\",\"attention\":-0.0003937351,\"sentence\":0,\"label\":\"O\"},{\"token\":\"16-goal\",\"attention\":-0.0024220345,\"sentence\":0,\"label\":\"O\"},{\"token\":\"margin\",\"attention\":0.0026563238,\"sentence\":0,\"label\":\"O\"},{\"token\":\"while\",\"attention\":-0.001348516,\"sentence\":0,\"label\":\"O\"},{\"token\":\"hoping\",\"attention\":0.0001820441,\"sentence\":0,\"label\":\"O\"},{\"token\":\"the\",\"attention\":-0.0049440153,\"sentence\":0,\"label\":\"O\"},{\"token\":\"United\",\"attention\":0.0020397764,\"sentence\":0,\"label\":\"O\"},{\"token\":\"States\",\"attention\":-0.0017957012,\"sentence\":0,\"label\":\"O\"},{\"token\":\"would\",\"attention\":0.0024788261,\"sentence\":0,\"label\":\"O\"},{\"token\":\"lose\",\"attention\":0.0057712258,\"sentence\":0,\"label\":\"O\"},{\"token\":\"against\",\"attention\":-0.0010732559,\"sentence\":0,\"label\":\"O\"},{\"token\":\"Russia\",\"attention\":0.0019592326,\"sentence\":0,\"label\":\"O\"},{\"token\":\"later\",\"attention\":-0.0009267218,\"sentence\":0,\"label\":\"O\"},{\"token\":\"in\",\"attention\":-0.0028129478,\"sentence\":0,\"label\":\"O\"},{\"token\":\"the\",\"attention\":-0.0049440153,\"sentence\":0,\"label\":\"O\"},{\"token\":\"day\",\"attention\":0.004652556,\"sentence\":0,\"label\":\"O\"},{\"token\":\".\",\"attention\":0.0005335736,\"sentence\":0,\"label\":\"O\"},{\"token\":\"The\",\"attention\":-0.0036663993,\"sentence\":0,\"label\":\"O\"},{\"token\":\"Latvians\",\"attention\":0.002276656,\"sentence\":0,\"label\":\"O\"},{\"token\":\"needed\",\"attention\":0.0017944238,\"sentence\":0,\"label\":\"O\"},{\"token\":\"to\",\"attention\":-0.001162009,\"sentence\":0,\"label\":\"O\"},{\"token\":\"beat\",\"attention\":-0.0009340789,\"sentence\":0,\"label\":\"O\"},{\"token\":\"Kazakhstan\",\"attention\":0.0000199094,\"sentence\":0,\"label\":\"O\"},{\"token\":\"and\",\"attention\":0.0013523418,\"sentence\":0,\"label\":\"O\"},{\"token\":\"erase\",\"attention\":0.0040595364,\"sentence\":0,\"label\":\"O\"},{\"token\":\"a\",\"attention\":0.0014214688,\"sentence\":0,\"label\":\"O\"},{\"token\":\"huge\",\"attention\":-0.0003937351,\"sentence\":0,\"label\":\"O\"},{\"token\":\"16-goal\",\"attention\":-0.0024220345,\"sentence\":0,\"label\":\"O\"},{\"token\":\"margin\",\"attention\":0.0026563238,\"sentence\":0,\"label\":\"O\"},{\"token\":\"while\",\"attention\":-0.001348516,\"sentence\":0,\"label\":\"O\"},{\"token\":\"hoping\",\"attention\":0.0001820441,\"sentence\":0,\"label\":\"O\"},{\"token\":\"the\",\"attention\":-0.0049440153,\"sentence\":0,\"label\":\"O\"},{\"token\":\"United\",\"attention\":0.0020397764,\"sentence\":0,\"label\":\"O\"},{\"token\":\"States\",\"attention\":-0.0017957012,\"sentence\":0,\"label\":\"O\"},{\"token\":\"would\",\"attention\":0.0024788261,\"sentence\":0,\"label\":\"O\"},{\"token\":\"lose\",\"attention\":0.0057712258,\"sentence\":0,\"label\":\"O\"},{\"token\":\"against\",\"attention\":-0.0010732559,\"sentence\":0,\"label\":\"O\"},{\"token\":\"Russia\",\"attention\":0.0019592326,\"sentence\":0,\"label\":\"O\"},{\"token\":\"later\",\"attention\":-0.0009267218,\"sentence\":0,\"label\":\"O\"},{\"token\":\"in\",\"attention\":-0.0028129478,\"sentence\":0,\"label\":\"O\"},{\"token\":\"the\",\"attention\":-0.0049440153,\"sentence\":0,\"label\":\"O\"},{\"token\":\"day\",\"attention\":0.004652556,\"sentence\":0,\"label\":\"O\"},{\"token\":\".\",\"attention\":0.0005335736,\"sentence\":0,\"label\":\"O\"},{\"token\":\"Cricket\",\"attention\":-0.0002028945,\"sentence\":1,\"label\":\"O\"},{\"token\":\"'s\",\"attention\":-0.0013148994,\"sentence\":1,\"label\":\"O\"},{\"token\":\"world\",\"attention\":0.0032680617,\"sentence\":1,\"label\":\"O\"},{\"token\":\"authority\",\"attention\":-0.0015928645,\"sentence\":1,\"label\":\"O\"},{\"token\":\",\",\"attention\":-0.0004186843,\"sentence\":1,\"label\":\"O\"},{\"token\":\"the\",\"attention\":-0.0049440153,\"sentence\":1,\"label\":\"O\"},{\"token\":\"ICC\",\"attention\":0.0016464078,\"sentence\":1,\"label\":\"O\"},{\"token\":\",\",\"attention\":-0.0004186843,\"sentence\":1,\"label\":\"O\"},{\"token\":\"suspended\",\"attention\":0.0021978177,\"sentence\":1,\"label\":\"O\"},{\"token\":\"Butt\",\"attention\":0.0024917338,\"sentence\":1,\"label\":\"O\"},{\"token\":\",\",\"attention\":-0.0004186843,\"sentence\":1,\"label\":\"O\"},{\"token\":\"Asif\",\"attention\":0.0012006464,\"sentence\":1,\"label\":\"O\"},{\"token\":\"and\",\"attention\":0.0013523418,\"sentence\":1,\"label\":\"O\"},{\"token\":\"Amir\",\"attention\":-0.0011378865,\"sentence\":1,\"label\":\"O\"},{\"token\":\"last\",\"attention\":-0.0003281923,\"sentence\":1,\"label\":\"O\"},{\"token\":\"week\",\"attention\":-0.0021902628,\"sentence\":1,\"label\":\"O\"},{\"token\":\"pending\",\"attention\":-0.0031534929,\"sentence\":1,\"label\":\"O\"},{\"token\":\"its\",\"attention\":-0.0026369088,\"sentence\":1,\"label\":\"O\"},{\"token\":\"own\",\"attention\":-0.0009822007,\"sentence\":1,\"label\":\"O\"},{\"token\":\"investigation\",\"attention\":-0.0046449187,\"sentence\":1,\"label\":\"O\"},{\"token\":\".\",\"attention\":0.0005335736,\"sentence\":1,\"label\":\"O\"}];  // We are heavily using the similarties\n",
       "                         // between js and json syntax.\n",
       "opts = {\n",
       "  lineHeight: 16,\n",
       "  width: 900,\n",
       "  height: 600,\n",
       "  linePadding: 10\n",
       "}\n",
       "chart = new TextChart(nouns, opts);\n",
       "chart.draw(\"text-container\");\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_text_template = Template('''\n",
    "var nouns = $json_data;  // We are heavily using the similarties\n",
    "                         // between js and json syntax.\n",
    "opts = {\n",
    "  lineHeight: 16,\n",
    "  width: 900,\n",
    "  height: 600,\n",
    "  linePadding: 10\n",
    "}\n",
    "chart = new TextChart(nouns, opts);\n",
    "chart.draw(\"text-container\");\n",
    "''')\n",
    "\n",
    "html_template = Template('''\n",
    "    <div id='text-container'></div>\n",
    "    <script>$js_text</script>\n",
    "''')\n",
    "\n",
    "js_text = js_text_template.substitute({\n",
    "    'json_data': json_data\n",
    "})\n",
    "\n",
    "HTML(html_template.substitute({'js_text': js_text}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:am_env]",
   "language": "python",
   "name": "conda-env-am_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
